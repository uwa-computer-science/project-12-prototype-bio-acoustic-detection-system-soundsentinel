{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths for the audio files and corresponding CSV annotations\n",
    "audio_files = ['../data/Development_set/Development_Set/Training_Set/MT/dcase_MK1.wav', '../data/Development_set/Development_Set/Training_Set/MT/dcase_MK2.wav']\n",
    "csv_files = ['../data/Development_set/Development_Set/Training_Set/MT/dcase_MK1.csv', '../data/Development_set/Development_Set/Training_Set/MT/dcase_MK2.csv']\n",
    "\n",
    "# Output directory for AFE segments\n",
    "output_dir = 'processed_segments'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from Esther's preprocessing code for audio segmentation from processed_segments.py\n",
    "# Target sampling rate\n",
    "sr = 8000\n",
    "\n",
    "# Iterate through each audio file and its corresponding CSV annotation file\n",
    "for audio_file, csv_file in zip(audio_files, csv_files):\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(audio_file, sr=sr)\n",
    "\n",
    "    # Load the CSV annotations\n",
    "    annotations = pd.read_csv(csv_file)\n",
    "\n",
    "    # Iterate over each row in the CSV to extract annotation details\n",
    "    for i, annotation in annotations.iterrows():\n",
    "        # Skip the segment if any of the annotation columns contain 'UNK'\n",
    "        if 'UNK' in [annotation['SNMK'], annotation['CCMK'], annotation['AGGM'], annotation['SOCM']]:\n",
    "            continue\n",
    "\n",
    "        start_time = annotation['Starttime']\n",
    "        end_time = annotation['Endtime']\n",
    "\n",
    "        # Calculate the event center time\n",
    "        event_center = (start_time + end_time) / 2\n",
    "\n",
    "        # Calculate the segment start and end times to ensure a 1-second duration\n",
    "        segment_start = max(0, event_center - 0.5)  # Ensure the start time is not negative\n",
    "        segment_end = segment_start + 1.0  # End time is 1 second after the start time\n",
    "\n",
    "        # Extract the segment from the audio file\n",
    "        start_sample = int(segment_start * sr)\n",
    "        end_sample = int(segment_end * sr)\n",
    "        segment = y[start_sample:end_sample]\n",
    "\n",
    "        # If the segment is less than 1 second, pad it with zeros\n",
    "        if len(segment) < sr:\n",
    "            segment = np.pad(segment, (0, sr - len(segment)), 'constant')\n",
    "\n",
    "        # Determine the label based on the annotation\n",
    "        if annotation['SNMK'] == 'POS':\n",
    "            label = 1  # SNMK\n",
    "        elif annotation['CCMK'] == 'POS':\n",
    "            label = 2  # CCMK\n",
    "        elif annotation['AGGM'] == 'POS':\n",
    "            label = 3  # AGGM\n",
    "        elif annotation['SOCM'] == 'POS':\n",
    "            label = 4  # SOCM\n",
    "        else:\n",
    "            label = 7  # unknown\n",
    "\n",
    "        # Create the output filename based on the audio file name, label, and segment index\n",
    "        output_filename = os.path.join(output_dir, f'{os.path.basename(audio_file).replace(\".wav\", \"\")}_segment_{i+1}_label_{label}.wav')\n",
    "\n",
    "        # Save the segment as a WAV file using the soundfile library\n",
    "        sf.write(output_filename, segment, sr)\n",
    "\n",
    "    # Process background noise segments\n",
    "    no_event_segments = []\n",
    "    for i in range(len(y) // sr):\n",
    "        segment_start = i * sr\n",
    "        segment_end = segment_start + sr\n",
    "        segment = y[segment_start:segment_end]\n",
    "\n",
    "        # Check if the segment overlaps with any event\n",
    "        overlaps = any(start_sample <= segment_start <= end_sample or start_sample <= segment_end <= end_sample\n",
    "                       for start_sample, end_sample in zip(annotations['Starttime'] * sr, annotations['Endtime'] * sr))\n",
    "\n",
    "        if not overlaps:\n",
    "            no_event_segments.append(segment)\n",
    "\n",
    "    # Randomly select the same number of no-event segments as there are event segments\n",
    "    np.random.shuffle(no_event_segments)\n",
    "    selected_no_event_segments = no_event_segments[:len(annotations)]\n",
    "\n",
    "    # Save the no-event segments with label 0 (background noise)\n",
    "    for i, segment in enumerate(selected_no_event_segments):\n",
    "        output_filename = os.path.join(output_dir, f'segment_{os.path.basename(audio_file).replace(\".wav\", \"\")}_{i+1}_label_0.wav')\n",
    "        sf.write(output_filename, segment, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Switch off warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# - Import numpy\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# - Import the plotting library\n",
    "import sys\n",
    "!{sys.executable} -m pip install --quiet matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = [16, 10]\n",
    "plt.rcParams[\"figure.dpi\"] = 300\n",
    "\n",
    "# - Rich printing\n",
    "try:\n",
    "    from rich import print\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - import AFE\n",
    "from rockpool.devices.xylo.syns61201 import AFESim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sampling frequency (8000.0) must be at least 6 times the highest BPF centre freq. (i.e. >101640 Hz)\n                The main reason is that the microphone produces THD (third-order distortion) which may fallback into the wrong frequency\n                if the sampling frequency is not large enough.\n                ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m                         \u001b[38;5;66;03m# Seed for mistmatch generation\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# - Initialize the AFE simulation, and convert it to a high-level `TimedModule`\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m afe \u001b[38;5;241m=\u001b[39m \u001b[43mAFESim\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraster_period\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mraster_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_spike_per_raster_period\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_spike_per_raster_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_noise\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43madd_noise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_offset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43madd_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_mismatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43madd_mismatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtimed()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/capstone/lib/python3.8/site-packages/rockpool/nn/modules/module.py:689\u001b[0m, in \u001b[0;36mPostInitMetaMixin.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;66;03m# - Instantiate the object\u001b[39;00m\n\u001b[0;32m--> 689\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;66;03m# - Check for a `__post_init__` method\u001b[39;00m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__post_init__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/capstone/lib/python3.8/site-packages/rockpool/devices/xylo/syns61201/afe_sim_empirical.py:201\u001b[0m, in \u001b[0;36mAFESim.__init__\u001b[0;34m(self, fs, raster_period, max_spike_per_raster_period, add_noise, add_offset, add_mismatch, seed, num_workers, *args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# - Check the filters w.r.t the sampling frequency\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mFs \u001b[38;5;241m<\u001b[39m (\u001b[38;5;241m6\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdesign_fcs)):\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mSampling frequency (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mFs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) must be at least 6 times the highest BPF centre freq. (i.e. >\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m6\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39mnp\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdesign_fcs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Hz)\u001b[39m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124m        The main reason is that the microphone produces THD (third-order distortion) which may fallback into the wrong frequency\u001b[39m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124m        if the sampling frequency is not large enough.\u001b[39m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    206\u001b[0m     )\n\u001b[1;32m    208\u001b[0m \u001b[38;5;66;03m# - nominal/design Bandwidths of the filters\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdesign_bws: P_ndarray \u001b[38;5;241m=\u001b[39m SimulationParameter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdesign_fcs \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ)\n",
      "\u001b[0;31mValueError\u001b[0m: Sampling frequency (8000.0) must be at least 6 times the highest BPF centre freq. (i.e. >101640 Hz)\n                The main reason is that the microphone produces THD (third-order distortion) which may fallback into the wrong frequency\n                if the sampling frequency is not large enough.\n                "
     ]
    }
   ],
   "source": [
    "# - AFE parameters\n",
    "\n",
    "fs = 8e3                          # The sampling frequency of the input, in Hz\n",
    "raster_period = 10e-3               # The output rasterisation time-step in seconds\n",
    "max_spike_per_raster_period = 15    # Maximum number of events per output time-step\n",
    "\n",
    "add_noise = False                    # Enables / disables simulated noise generated by the AFE\n",
    "add_offset = False                 # Add mismatch offset to each filter\n",
    "add_mismatch = False                 # Add simualted mismatch to filter parameters\n",
    "seed = None                         # Seed for mistmatch generation\n",
    "\n",
    "# - Initialize the AFE simulation, and convert it to a high-level `TimedModule`\n",
    "\n",
    "afe = AFESim(\n",
    "        fs = fs,\n",
    "        raster_period = raster_period,\n",
    "        max_spike_per_raster_period = max_spike_per_raster_period,\n",
    "        add_noise = add_noise,\n",
    "        add_offset = add_offset,\n",
    "        add_mismatch = add_mismatch,\n",
    "        seed = seed,\n",
    ").timed()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
