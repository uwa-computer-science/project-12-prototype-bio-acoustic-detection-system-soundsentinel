{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Labels distribution: tensor([1294,   95, 1046,   53,   40], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nisar\\AppData\\Local\\Temp\\ipykernel_31552\\578204215.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  labels_tensor = torch.load(\"C:/Users/nisar/github-classroom/uwa-computer-science/project-12-prototype-bio-acoustic-detection-system-soundsentinel/tensors/labels_tensor.pt\")\n",
      "C:\\Users\\nisar\\AppData\\Local\\Temp\\ipykernel_31552\\578204215.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  spikes_tensor = torch.load(\"C:/Users/nisar/github-classroom/uwa-computer-science/project-12-prototype-bio-acoustic-detection-system-soundsentinel/tensors/spike_data_tensor.pt\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Load tensor\n",
    "labels_tensor = torch.load(\"C:/Users/nisar/github-classroom/uwa-computer-science/project-12-prototype-bio-acoustic-detection-system-soundsentinel/tensors/labels_tensor.pt\")\n",
    "spikes_tensor = torch.load(\"C:/Users/nisar/github-classroom/uwa-computer-science/project-12-prototype-bio-acoustic-detection-system-soundsentinel/tensors/spike_data_tensor.pt\")\n",
    "\n",
    "label_distribution = torch.bincount(labels_tensor)\n",
    "print(f'Original Labels distribution: {label_distribution}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of downsampled label 0 samples: 1046\n",
      "Number of target label 1 samples: 1046\n",
      "Balanced dataset length: 2092\n",
      "Filtered Labels distribution after processing: tensor([1046, 1046], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class CCMKDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, spikes_tensor, labels_tensor, target_label=2):\n",
    "        self.spikes_tensor = spikes_tensor\n",
    "        self.labels_tensor = labels_tensor\n",
    "        self.target_label = target_label\n",
    "\n",
    "        # Step 1: Ignore labels 1, 3, and 4\n",
    "        valid_mask = (self.labels_tensor == 0) | (self.labels_tensor == target_label)\n",
    "        self.spikes_tensor = self.spikes_tensor[valid_mask]\n",
    "        self.labels_tensor = self.labels_tensor[valid_mask]\n",
    "\n",
    "        # Convert the target label (2) to 1 (positive sample)\n",
    "        self.labels_tensor[self.labels_tensor == target_label] = 1\n",
    "\n",
    "        # Step 2: Downsample label 0 (background noise) to match the number of target samples (label 2 -> now 1)\n",
    "        label_0_indices = torch.where(self.labels_tensor == 0)[0]\n",
    "        label_1_indices = torch.where(self.labels_tensor == 1)[0]\n",
    "\n",
    "        # print samples\n",
    "        #print(f\"Number of label 0 samples before downsampling: {len(label_0_indices)}\")\n",
    "        #print(f\"Number of label 1 samples (after converting target label 2 to 1): {len(label_1_indices)}\")\n",
    "\n",
    "        num_samples = min(len(label_1_indices), len(label_0_indices))\n",
    "\n",
    "        # Randomly sample from label 0 and label 1 indices\n",
    "        selected_label_0_indices = torch.tensor(np.random.choice(label_0_indices.cpu(), size=num_samples, replace=False))\n",
    "        selected_label_1_indices = torch.tensor(np.random.choice(label_1_indices.cpu(), size=num_samples, replace=False))\n",
    "\n",
    "        # Combine the downsampled label 0 indices with label 1 indices\n",
    "        balanced_indices = torch.cat([selected_label_0_indices, selected_label_1_indices])\n",
    "\n",
    "        # print data after samples\n",
    "        print(f\"Number of downsampled label 0 samples: {len(selected_label_0_indices)}\")\n",
    "        print(f\"Number of target label 1 samples: {len(selected_label_1_indices)}\")\n",
    "        print(f\"Balanced dataset length: {len(balanced_indices)}\")\n",
    "\n",
    "        # Apply the balanced indices to spikes and labels\n",
    "        self.spikes_tensor = self.spikes_tensor[balanced_indices]\n",
    "        self.labels_tensor = self.labels_tensor[balanced_indices]\n",
    "\n",
    "        # Debugging: Check the distribution of labels after processing\n",
    "        print(f\"Filtered Labels distribution after processing: {torch.bincount(self.labels_tensor.int())}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_tensor)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.spikes_tensor[idx], self.labels_tensor[idx]\n",
    "\n",
    "dataset = CCMKDataset(spikes_tensor=spikes_tensor, labels_tensor=labels_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "\n",
    "\n",
    "# Balance the dataset by selecting equal samples from both classes\n",
    "label_0_indices = torch.where(dataset.labels_tensor == 0)[0]\n",
    "label_1_indices = torch.where(dataset.labels_tensor == 1)[0]\n",
    "\n",
    "dataset_0 = torch.utils.data.Subset(dataset, label_0_indices)\n",
    "dataset_1 = torch.utils.data.Subset(dataset, label_1_indices)\n",
    "\n",
    "# Split size\n",
    "train_size_0 = int(0.8 * len(dataset_0))\n",
    "val_size_0 = int(0.1 * len(dataset_0))\n",
    "test_size_0 = len(dataset_0) - train_size_0 - val_size_0\n",
    "\n",
    "train_size_1 = int(0.8 * len(dataset_1))\n",
    "val_size_1 = int(0.1 * len(dataset_1))\n",
    "test_size_1 = len(dataset_1) - train_size_1 - val_size_1\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset_0, val_dataset_0, test_dataset_0 = random_split(dataset_0, [train_size_0, val_size_0, test_size_0], generator=torch.Generator().manual_seed(42))\n",
    "train_dataset_1, val_dataset_1, test_dataset_1 = random_split(dataset_1, [train_size_1, val_size_1, test_size_1], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# Combine splits from both classes\n",
    "train_dataset = torch.utils.data.ConcatDataset([train_dataset_0, train_dataset_1])\n",
    "val_dataset = torch.utils.data.ConcatDataset([val_dataset_0, val_dataset_1])\n",
    "test_dataset = torch.utils.data.ConcatDataset([test_dataset_0, test_dataset_1])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching data for train_loader_gpu.pkl\n",
      "Caching data for val_loader_gpu.pkl\n",
      "Caching data for test_loader_gpu.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "# Directory to store cached data\n",
    "cache_dir = 'dataloader_cache'\n",
    "if not os.path.exists(cache_dir):\n",
    "    os.makedirs(cache_dir)\n",
    "\n",
    "def cache_loader_to_gpu(loader, cache_name):\n",
    "    cache_path = os.path.join(cache_dir, cache_name)\n",
    "    \n",
    "    # Check if the cache exists\n",
    "    if os.path.exists(cache_path):\n",
    "        print(f\"Loading cached data for {cache_name} from disk\")\n",
    "        with open(cache_path, 'rb') as f:\n",
    "            cached_data = pickle.load(f)\n",
    "        \n",
    "        # Move cached data to GPU\n",
    "        cached_data_gpu = [(inputs.to('cuda'), targets.to('cuda')) for inputs, targets in cached_data]\n",
    "        return cached_data_gpu\n",
    "    \n",
    "    # If no cache, load data using the original loader and cache it\n",
    "    print(f\"Caching data for {cache_name}\")\n",
    "    data_list = []\n",
    "    for data in loader:\n",
    "        data_list.append((data[0].to('cuda'), data[1].to('cuda')))  # Move data to GPU immediately\n",
    "    \n",
    "    # Save the data to cache on disk (CPU version)\n",
    "    with open(cache_path, 'wb') as f:\n",
    "        pickle.dump([(inputs.cpu(), targets.cpu()) for inputs, targets in data_list], f)\n",
    "    \n",
    "    return data_list  # Return GPU version of the data\n",
    "\n",
    "# Example usage with train_loader, val_loader, and test_loader\n",
    "train_loader_cache = cache_loader_to_gpu(train_loader, 'train_loader_gpu.pkl')\n",
    "val_loader_cache = cache_loader_to_gpu(val_loader, 'val_loader_gpu.pkl')\n",
    "test_loader_cache = cache_loader_to_gpu(test_loader, 'test_loader_gpu.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache directory is located at: c:\\Users\\nisar\\github-classroom\\uwa-computer-science\\project-12-prototype-bio-acoustic-detection-system-soundsentinel\\angela19sep\\dataloader_cache\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the absolute path of the cache directory\n",
    "cache_dir = 'dataloader_cache'\n",
    "absolute_cache_path = os.path.abspath(cache_dir)\n",
    "print(f\"Cache directory is located at: {absolute_cache_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the cached data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached data from C:/Users/nisar/github-classroom/uwa-computer-science/project-12-prototype-bio-acoustic-detection-system-soundsentinel/dataloader_cache\\train_loader_gpu.pkl\n",
      "Loading cached data from C:/Users/nisar/github-classroom/uwa-computer-science/project-12-prototype-bio-acoustic-detection-system-soundsentinel/dataloader_cache\\val_loader_gpu.pkl\n",
      "Loading cached data from C:/Users/nisar/github-classroom/uwa-computer-science/project-12-prototype-bio-acoustic-detection-system-soundsentinel/dataloader_cache\\test_loader_gpu.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Directory where the cached data is stored\n",
    "cache_dir = 'C:/Users/nisar/github-classroom/uwa-computer-science/project-12-prototype-bio-acoustic-detection-system-soundsentinel/dataloader_cache'\n",
    "\n",
    "# Function to load cached data\n",
    "def load_cached_data(cache_name):\n",
    "    cache_path = os.path.join(cache_dir, cache_name)\n",
    "    \n",
    "    # Check if cache file exists\n",
    "    if os.path.exists(cache_path):\n",
    "        print(f\"Loading cached data from {cache_path}\")\n",
    "        with open(cache_path, 'rb') as f:\n",
    "            cached_data = pickle.load(f)\n",
    "        return cached_data\n",
    "    else:\n",
    "        print(f\"Cache file {cache_path} not found.\")\n",
    "        return None\n",
    "\n",
    "# Load cached data loaders\n",
    "train_loader_cache = load_cached_data('train_loader_gpu.pkl')\n",
    "val_loader_cache = load_cached_data('val_loader_gpu.pkl')\n",
    "test_loader_cache = load_cached_data('test_loader_gpu.pkl')\n",
    "\n",
    "# Ensure the cached data is on the GPU if necessary\n",
    "def move_data_to_gpu(cached_loader):\n",
    "    gpu_loader = [(inputs.to('cuda'), targets.to('cuda')) for inputs, targets in cached_loader]\n",
    "    return gpu_loader\n",
    "\n",
    "# Move to GPU if needed (only if the data is not already on GPU)\n",
    "train_loader_cache = move_data_to_gpu(train_loader_cache)\n",
    "val_loader_cache = move_data_to_gpu(val_loader_cache)\n",
    "test_loader_cache = move_data_to_gpu(test_loader_cache)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
